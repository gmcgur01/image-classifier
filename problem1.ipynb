{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neural_network\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2102, 784)\n",
      "(2102,)\n",
      "(600, 784)\n",
      "(600,)\n",
      "[2 0 3 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.abspath(\"data_fashion/\")\n",
    "\n",
    "train_x = pd.read_csv(os.path.join(data_dir, \"x_train.csv\")).to_numpy()\n",
    "train_y = pd.read_csv(os.path.join(data_dir, \"y_train.csv\")).to_numpy()[:,1].astype(np.int32)\n",
    "\n",
    "valid_x = pd.read_csv(os.path.join(data_dir, \"x_valid.csv\")).to_numpy()\n",
    "valid_y = pd.read_csv(os.path.join(data_dir, \"y_valid.csv\")).to_numpy()[:,1].astype(np.int32)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)\n",
    "\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mlp = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(800,),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    max_iter=10000,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# activation, solver, hidden layer, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom splitter for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom splitter code\n",
    "\n",
    "xall_LF = np.vstack([train_x, valid_x])\n",
    "yall_L = np.hstack([train_y, valid_y])\n",
    "\n",
    "valid_indicators_L = np.hstack([\n",
    "    -1 * np.ones(train_y.size),\n",
    "    0  * np.ones(valid_y.size),\n",
    "    ])\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Grid Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_hyperparam_grid = dict(\n",
    "    hidden_layer_sizes=[(16,), (32,), (64,), (128,), (256,), (512,), (1024,)],\n",
    "    alpha=np.logspace(-5, 5, 11)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    base_mlp, mlp_hyperparam_grid, scoring='balanced_accuracy', \n",
    "    cv=my_splitter, return_train_score=True, refit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit grid searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgemcgurkin/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/georgemcgurkin/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp_grid_searcher.fit(xall_LF, yall_L)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
